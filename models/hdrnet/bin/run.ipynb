{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import setproctitle\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import sys\n",
    "sys.path.append('/home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet')\n",
    "import models as models\n",
    "import data_pipeline_lupin as dp\n",
    "import metrics as metrics\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"[%(process)d] %(levelname)s %(filename)s:%(lineno)s | %(message)s\")\n",
    "log = logging.getLogger(\"train\")\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args,model_params):\n",
    "    setproctitle.setproctitle('hdrnet_run')\n",
    "    data_pipe = getattr(dp, args.data_pipeline)\n",
    "    mdl = getattr(models, model_params['model_name'])\n",
    "    with tf.compat.v1.variable_scope('eval_data'):\n",
    "        eval_data_pipeline = data_pipe(\n",
    "          args.input,\n",
    "          shuffle=False,\n",
    "          batch_size=1, nthreads=1,\n",
    "          fliplr=False, flipud=False, rotate=False,\n",
    "          random_crop=False,\n",
    "          output_resolution = args.output_resolution)\n",
    "    eval_samples = eval_data_pipeline.samples\n",
    "    with tf.compat.v1.variable_scope('inference'):\n",
    "        eval_prediction = mdl.inference(\n",
    "            eval_samples['lowres_input'], eval_samples['image_input'],\n",
    "            model_params, is_training=False)\n",
    "#     output = tf.cast(255.0*tf.squeeze(tf.clip_by_value(eval_prediction, 0, 1)), tf.uint8)\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # Do not canibalize the entire GPU\n",
    "    sv = tf.compat.v1.train.Supervisor(logdir=args.checkpoint_dir)\n",
    "    psnr = 0\n",
    "    ssim = 0\n",
    "    with sv.managed_session(config=config) as sess:\n",
    "        while True:\n",
    "            if sv.should_stop():\n",
    "                log.info(\"stopping supervisor\")\n",
    "                break\n",
    "            try:\n",
    "                for it in tqdm(range(eval_data_pipeline.nsamples)):\n",
    "                    prediction, label = sess.run([eval_prediction,eval_samples['image_output']])\n",
    "                    prediction = np.squeeze(prediction)\n",
    "                    label = np.squeeze(label)\n",
    "                    psnr += compare_psnr(prediction,label,data_range=1.0)\n",
    "                    ssim += compare_ssim(prediction,label,data_range=1.0, multichannel = True)\n",
    "# #                     fname = os.path.splitext(os.path.basename(input_path))[0]\n",
    "# #                     fname = input_path.split('/')[-1]\n",
    "#                     fname = input_path\n",
    "#                     output_path = os.path.join(args.output, fname)\n",
    "#                     basedir = os.path.dirname(output_path)\n",
    "#                     if not os.path.exists(basedir):\n",
    "#                         os.makedirs(basedir)\n",
    "#                     skimage.io.imsave(output_path, out_)\n",
    "                break\n",
    "            except tf.errors.AbortedError:\n",
    "                log.error(\"Aborted\")\n",
    "                break\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "    psnr /= 767\n",
    "    ssim /= 767\n",
    "    print(psnr,ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/data_pipeline_lupin.py:184: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/data_pipeline_lupin.py:184: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:373: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:373: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:319: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:319: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/data_pipeline_lupin.py:213: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/data_pipeline_lupin.py:213: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/data_pipeline_lupin.py:107: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/data_pipeline_lupin.py:107: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:506 | From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-b8306461d401>:21: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From <ipython-input-3-b8306461d401>:21: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/checkpoint/psnr_best-322175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] INFO saver.py:1293 | Restoring parameters from /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/checkpoint/psnr_best-322175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] WARNING deprecation.py:323 | From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] INFO session_manager.py:505 | Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] INFO session_manager.py:508 | Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] INFO supervisor.py:737 | Starting standard services.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/checkpoint/model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] INFO supervisor.py:1117 | Saving checkpoint to path /home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/checkpoint/model.ckpt\n",
      "[22315] INFO supervisor.py:743 | Starting queue runners.\n",
      "  0%|          | 0/767 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] INFO supervisor.py:1050 | Recording summary at step None.\n",
      " 67%|██████▋   | 515/767 [01:59<00:55,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22315] INFO supervisor.py:1050 | Recording summary at step None.\n",
      "100%|██████████| 767/767 [02:58<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.400723839855633 0.5410175975751349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "req_grp = parser.add_argument_group('required')\n",
    "req_grp.add_argument('--checkpoint_dir', default= '/home/lupin/PhotoEnhance/hdrnet_lupin/hdrnet/checkpoint')\n",
    "req_grp.add_argument('--input', default='/home/lupin/PhotoEnhance/dataset/SICE/Part2/test.txt')\n",
    "req_grp.add_argument('--output', default='/home/lupin/PhotoEnhance/hdrnet_lupin/output')\n",
    "req_grp.add_argument('--lowres_input', default=None, help='path to the lowres, TF inputs')\n",
    "model_grp = parser.add_argument_group('model_params')\n",
    "model_grp.add_argument('--model_name', default=models.__all__[0], type=str, help='classname of the model to use.', choices=models.__all__)\n",
    "model_grp.add_argument('--data_pipeline', default='ImageFilesDataPipeline', help='classname of the data pipeline to use.', choices=dp.__all__)\n",
    "model_grp.add_argument('--net_input_size', default=256, type=int, help=\"size of the network's lowres image input.\")\n",
    "model_grp.add_argument('--output_resolution', default=[900, 1200], type=int, nargs=2, help='resolution of the output image.')\n",
    "model_grp.add_argument('--batch_norm', dest='batch_norm', action='store_true', help='normalize batches. If False, uses the moving averages.')\n",
    "model_grp.add_argument('--nobatch_norm', dest='batch_norm', action='store_false')\n",
    "model_grp.add_argument('--channel_multiplier', default=1, type=int,  help='Factor to control net throughput (number of intermediate channels).')\n",
    "model_grp.add_argument('--guide_complexity', default=16, type=int,  help='Control complexity of the guide network.')\n",
    "model_grp.add_argument('--luma_bins', default=8, type=int,  help='Number of BGU bins for the luminance.')\n",
    "model_grp.add_argument('--spatial_bin', default=16, type=int,  help='Size of the spatial BGU bins (pixels).')\n",
    "parser.set_defaults(batch_norm=True)\n",
    "args = parser.parse_args(args = [])\n",
    "model_params = {}\n",
    "for a in model_grp._group_actions:\n",
    "    model_params[a.dest] = getattr(args, a.dest, None)\n",
    "main(args,model_params)\n",
    "#17.400723839855633 0.5410175975751349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(3, 3,15,15)\n",
    "# torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "B = torch.max(A,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 15, 15])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.mean(A,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 15, 15])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
